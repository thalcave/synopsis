1)Know When to Use an Active Object Instead of a Mutex
drdobbs, Herb Sutter

a shared log file object - how to avoid contention?

 Use Buffering, Preferably Asynchronous
  - one typical strategy for dealing with high-latency operations is to introduce buffering.
synchronous = 	do the actual write on Nth time
async - caller thread writes into a queue, and a worker thread takes items off the queue and perform the writing

Guideline: Prefer to make high-contention and/or high-latency shared state, notably I/O,
be asynchronous and therefore inherently buffered.

If you have high-contention and/or high-latency shared state, especially I/O, prefer to make it asynchronous.
Doing so makes buffering implicit, because the buffering just happens as a side effect of the asynchrony

Active object pattern = decouples method execution from method invocation that reside in their own thread of control
the goal is to introduce concurrency, by using asynchronous method invocation and a scheduler for handling requests.[2]


Asynchronous method invocation
- a design pattern for asynchronous invocation of potentially long-running methods of an object

2) Break Amdahl's law: drdobbs, Herb Sutter
Amdahl's law:
p = amount of a program's processing that is fully "O(N)" parallelizable
s = rest of the program's work sequential O(1)
N = number of cores

Speedup = (s+p)/ (s+p/N)
as N increases to infinity, the best speedup we can ever get is (s+p)/s


Gustafson suggested, "it may be most realistic to assume that run time, not problem size, is constant."
Total Work ("best possible speedup") = s + Np
As N increases to infinity, the total work we can accomplish also increases to infinity.
In practice, this means that it increases until we can't make the problem any bigger or are bound on some other factor, such as memory or other I/O.




Writing Concurrent Systems, Part 3: Specialized Systems - David Chisnall, informit

a) Transactional Memory
- grouping a set of operations so that either all succeed or all fail
(The same basic mechanism is used in most modern filesystems in the form of journaling;
a filesystem modification either completes or the filesystem can be rolled back to the state before it started)

how it works:
- a thread completes modifications to shared memory without regard for what other threads might be doing,
recording every read and write that it is performing in a log.
- the one to make sure it does not adversely affect other operations in progress it's not the writer (as before),
but the reader, who after completing an entire transaction verifies that other threads have not concurrently
made changes to memory that it accessed in the past.
- this final operation, in which the changes of a transaction are validated and, if validation is successful,
made permanent, is called a commit.
- a transaction may also abort at any time, causing all of its prior changes to be rolled back or undone.
- if a transaction cannot be committed due to conflicting changes, it is typically aborted and re-executed from the beginning until it succeeds.

benefits:
- increased concurrency
- in realistic programs, conflicts arise rarely enough that there is an immense performance gain
downsides:
- the overhead associated with maintaining the log and the time spent committing transactions

stmmap


b) Map Reduce

two higher-order functions:
	one maps an input to an output
	the other combines outputs

In the simplest case:
	the maps can all happen independently, and then
	the reduce happens sequentially on all of the outputs
In a slightly more advanced implementation:
	individual nodes can perform a reduce on all of their mapped values, and then
	these can be further combined.

merge sort, 