Randomization is a powerful tool to improve algorithms with bad worst-case but good average-case complexity
	e.g randomly selecting a hash function
	
quicksort is typically 2-3 times faster than mergesort (operations in innermost loops are simpler)


-------------------------------------------------------------------------
stable sorting algorithms = maintain the relative order of records with equal keys (i.e., values)
	e.g if we are sorting pairs (i,j) only after (i), ...

1) Merge sort:
- O(n log n) comparison based sorting algorithm
- divide and conquer (recursively breaking down a problem into two or more sub-problems of the same (or related) type,
		      until these become simple enough to be solved directly.
		      The solutions to the sub-problems are then combined to give a solution to the original problem.)

merge sort:
1. If the list is of length 0 or 1, then it is already sorted. Otherwise:
	2. Divide the unsorted list into two sublists of about half the size.
	3. Sort each sublist recursively by re-applying merge sort.
	4. Merge the two sublists back into one sorted list

two main ideas to improve runtime:
- A small list will take fewer steps to sort than a large list.
- Fewer steps are required to construct a sorted list from two sorted lists than two unsorted lists

- useful for sorting data on disk that is too large to fit entirely into primary memory

mergeSort()
{
	if (array.size() <= 1)
		return array
		
	middle = array.size()/2
	left = mergeSort(left_array)
	right = mergeSort(rightArray)
	
	return merge2Sorted(left, right)
}


Best case: O(n logn)
Avg  case: O(n logn)
Worst case:O(n logn)

Space: O(n) --> merging is not done in place


2) Quicksort
Best case: O(n logn)
Avg  case: O(n logn)
Worst case:O(n^2)


Algorithm:
* pick pivot from list
* smaller elems go to minlist, greater elems go to maxlist
* recursively apply the steps above for minlist and maxlist
	concatenate(quicksort(minlist), pivot, quicksort(maxlist))

3) counting sort:
* sorting a collection of objects according to keys that are small integers
O(n+k): n - input size
	k - number of keys

space: O(n+k)


4) Radix sort
 * sorts data with integer keys by grouping keys by the individual digits which share the same significant position and value. 
 sort after last digit
 sort after second to last digit...
 
 
 time:  O(kN)
 space: O(k+N) 
 
 
5) Bucket (bin) sort: partition an array in a number of buckets, sort them and merge them
very effective when we are confident that the distribution of data will be roughly uniform

Steps:
1. set up array of initially empty buckets
2. scatter: go over initial array, putting each object in its bucket
3. sort each non-empty bucket
4. gather: visit the buckets in order and put all elements back into the original array

The most common variant of bucket sort operates on a list of n numeric inputs between zero and some maximum value M and divides the value range into n buckets each of size M/n.
Sorting names in a phone book --> 26 buckets

Avg  case: O(n+k)
Worst case:O(n^2)


6) Heap sort
step1: a heap is built out of the data
step2: a sorted array is created by repeatedly removing the largest element from the heap, and inserting it into the array. The heap is reconstructed after each removal. 

Best case: O(n logn)
Avg  case: O(n logn)
Worst case:O(n logn)



Merge sort: 
   *Advantages: suitable for linked list, suitable for external sort.
   *Disadvantages: need extra buffer holding the merged data.

Insertion/Selection sort: 
   *Advantages: easy to implement.
   *Disadvantages: too slow and become impractical when data is huge.

Heap sort: 
   *Advantages: don't need recursion. Suitable for large data.
   *Disadvantages: usually slower than merge sort and quick sort; unstable

Quick sort: 
   *Advantages: practical fastest.
   *Disadvantages: recursive, worst case too slow; unstable;


 
---------------------------------------------------------------------------------
Selection algorithm
* suitable for finding the kth smallest number in an array/list (e.g min, max, median)

a. sort the array (O(nlogn)) and select desired element
- efficient when many selections are needed
- lower time when using counting/radix sort

b. Partial selection sort:
* sort only the first k elements (using selection sort): find the minimum value and move it to the beginning, repeating on the remaining list until we have accumulated k elements, and then return the kth element
* complexity: O(kn) --> efficient if k is small

c. Quickselect:
Solution: uses the same overall approach as quicksort, choosing one element as a pivot and partitioning the data in two based on the pivot, accordingly as less than or greater than the pivot. 
 * However, instead of recursing into both sides, as in quicksort, quickselect only recurses into one side â€“ the side with the element it is searching for. 
 * This reduces the average complexity from O(n log n) (in quicksort) to O(n) (in quickselect)
 * it also partially sorts the data
 
Finding min and max:
- common solution takes 2 * N comparisons
- pair solution:
	iterate on pairs
	compare it1 with it2
		min will be compared with min_so_far
		max will be compared with max_so_far
 complexity: 3 comparisons per pair --> 3 * (N/2) comparisons -> 1.5 comparisons
 

---------------------------------------------------------------------------------
External sorting
- massive amounts of data which do not fit in memory

External merge sort: sorting 900MB with only 100MB available
Sort:
* read data in chunks of 100MB and sort it
* write sorted data on disk
* repeat until all data is sorted
Merge:
* read the first 10 MB of each sorted chunk and allocate a 10 MB output buffer (9*10 + 10 = 100MB)
* merge them, using a 9-way merge, store result in output; 
	when output is full, write it on disk; 
	whenever an input buffer is empty, FILL IT with the next 10MB of its associated chunk!!!

K-way merging: merge K sorted arrays into a single one
a. merge first 2 arrays, then merge result and the 3rd, result and the 4th...
b. keep K indexes (one for each array) and find the min, move the index of min etc
c. Use min-heap:
- take first element from each list and create a min-heap
- while the min-heap has elements:
	remove the data from the root and insert into output buffer
	get the listIndex for removed node (root)
	from the listIndex list get next element and insert it into minheap

min_heap = create_min_heap(lists)	//create min-heap with first element of each list
while (not min_heap.empty)		//while this min-heap is not empty
	celem = min_heap.root()		//take the root element = min element
	clist = celem.list_index	//take index of list
	
	result.add(celem)		//put current elem (min) in result
	min_heap.remove(root)		//delete root(min) from min-heap
	if lists[list_index].not_empty()//if list that contains current element is not empty, add the next elem in min-heap
		min_heap.insert(lists[list_index].front)
		lists[list_index].pop_front
	//if list is empty, go to next iteration




